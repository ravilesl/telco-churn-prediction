# Predicci贸n de Abandono de Clientes (Telco Churn Prediction)

Este proyecto implementa un pipeline de **aprendizaje autom谩tico** para predecir la tasa de abandono de clientes de una compa帽铆a de telecomunicaciones. El objetivo principal es identificar a los clientes en riesgo de irse (`Churn='Yes'`) para que la empresa pueda tomar medidas de retenci贸n proactivas.

El proyecto est谩 dise帽ado con una arquitectura modular y escalable, siguiendo las mejores pr谩cticas de **Ingenier铆a de MLOps**, lo que facilita su mantenimiento, depuraci贸n y la adici贸n de nuevos modelos o caracter铆sticas.

## Arquitectura del Proyecto

La estructura del repositorio est谩 organizada para separar las distintas etapas del pipeline de ML:

- **`main.py`**: El script principal que orquesta todo el flujo de trabajo, desde la carga de datos hasta el entrenamiento y la evaluaci贸n de modelos.
- **`src/`**: Directorio principal que contiene el c贸digo fuente del proyecto.
  - **`data/`**: Contiene la l贸gica para la carga y gesti贸n de los datos.
  - **`features/`**: M贸dulo para el preprocesamiento de datos y la ingenier铆a de caracter铆sticas.
  - **`models/`**: Contiene las definiciones de los modelos y la l贸gica para el ajuste de hiperpar谩metros.
  - **`pipelines/`**: M贸dulo que define y ejecuta el pipeline de entrenamiento completo.
  - **`utils/`**: Funciones de utilidad y herramientas de ayuda.
- **`notebooks/`**: Cuadernos de Jupyter/Colab para la exploraci贸n de datos y la demostraci贸n del pipeline.
- **`models/`**: Carpeta para guardar el modelo entrenado y serializado.
- **`assets/`**: Almacena los gr谩ficos y las visualizaciones de la evaluaci贸n del modelo.

## Archivos y M茅todos Clave

A continuaci贸n, se describen los componentes principales del proyecto:

###  `src/data/data_loader.py`

- **`load_raw_data(file_path)`**: Funci贸n que se encarga de cargar el archivo CSV del dataset.

###  `src/features/feature_engineering.py`

Este m贸dulo es fundamental para preparar los datos. Implementa varias estrategias de preprocesamiento y enriquecimiento:

- **`consolidate_categories(df)`**: Transforma valores como **"No internet service"** y **"No phone service"** a un valor unificado de **"No"**. Esta estrategia simplifica las categor铆as, reduciendo la dimensionalidad del dataset y ayudando a los modelos a generalizar mejor.
- **`create_features(df)`**: Aplica **ingenier铆a de caracter铆sticas** para generar nuevas variables a partir de las existentes, como:
  - **`InternetServiceCount`**: Un conteo de servicios de internet que el cliente tiene contratados.
  - **`tenure_contract_interaction`**: Una caracter铆stica de interacci贸n que combina el tiempo de permanencia (`tenure`) con el tipo de contrato, capturando la relaci贸n entre estos dos factores.
- **`preprocess_and_split(df, target)`**: Orquesta las transformaciones de datos, excluye la columna de identificaci贸n del cliente y prepara los datos para la entrada del modelo, definiendo las columnas num茅ricas y categ贸ricas para el `ColumnTransformer`.

###  `src/models/model_factory.py`

Este m贸dulo centraliza la creaci贸n y configuraci贸n de los modelos de machine learning.

- **`create_model_and_params(model_name)`**: Genera una instancia de un modelo de clasificaci贸n (ej. **XGBoost, LightGBM, RandomForest**) y su respectiva grilla de hiperpar谩metros para la optimizaci贸n. Se han ajustado los rangos de b煤squeda de par谩metros para explorar combinaciones que maximicen el rendimiento.

###  `src/pipelines/training_pipeline.py`

El coraz贸n del proyecto, donde se ejecuta el flujo de trabajo completo:

- **Detecci贸n de Desbalance de Clases**: El pipeline detecta autom谩ticamente si el dataset est谩 desbalanceado.
  - Si el desbalance es significativo, la m茅trica principal de optimizaci贸n cambia a **`f1-score`** en lugar de `accuracy`. Esto es crucial, ya que el F1-score es m谩s robusto para evaluar el rendimiento en la clase minoritaria (la de abandono), evitando que un modelo trivial con alta precisi贸n pero baja exhaustividad sea seleccionado.
- **Estrategias de Balanceo de Datos**: Para datasets desbalanceados, se prueban diferentes t茅cnicas de muestreo como **SMOTE**, **ADASYN**, y **Random Oversampling** en conjunto con la optimizaci贸n de hiperpar谩metros.
- **`GridSearchCV`**: Se utiliza para realizar una b煤squeda exhaustiva de los mejores hiperpar谩metros para cada modelo, asegurando el mejor rendimiento posible.

###  `src/evaluation/metrics_evaluator.py`

- **`evaluate_model(y_true, y_pred, model_name)`**: Genera el **reporte de clasificaci贸n** y la **matriz de confusi贸n** para el mejor modelo, proporcionando una evaluaci贸n detallada de su rendimiento en el conjunto de prueba.

## Estrategias Clave para Lograr Mejores Resultados

1.  **Enfoque en F1-Score**: Se prioriza el F1-Score sobre la precisi贸n, lo que garantiza que el modelo sea capaz de identificar eficazmente a los clientes en riesgo de abandono (alta exhaustividad), sin generar un n煤mero excesivo de falsos positivos (buena precisi贸n).
2.  **Ingenier铆a de Caracter铆sticas**: La creaci贸n de caracter铆sticas como el conteo de servicios y la interacci贸n de la permanencia y el contrato mejora la capacidad del modelo para capturar relaciones complejas en los datos.
3.  **Ajuste de Hiperpar谩metros**: El uso de `GridSearchCV` con rangos de b煤squeda ampliados permite encontrar configuraciones 贸ptimas para cada modelo.
4.  **Enfoque Hol铆stico**: El pipeline eval煤a m煤ltiples modelos y t茅cnicas de balanceo de clases de manera sistem谩tica, seleccionando el mejor desempe帽o global para la predicci贸n final.


### Opci贸n 1: 隆Ejecuta el Pipeline en Google Colab!

Puedes ejecutar el pipeline completo, desde la carga de datos hasta la evaluaci贸n del mejor modelo, directamente en Google Colab.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ravilesl/telco-churn-prediction/blob/main/notebooks/colab_runner.ipynb)

Este notebook contiene todo el c贸digo necesario, incluyendo la instalaci贸n de dependencias, lo que te permite explorar y ejecutar el proyecto sin necesidad de configuraciones locales.

### Opci贸n 2: Ejecutar Localmente
1.  Clona el repositorio: `git clone https://github.com/tu-usuario/telco-churn-prediction.git`
2.  Navega a la carpeta del proyecto: `cd telco-churn-prediction`
3.  Instala las dependencias: `pip install -r requirements.txt`
4.  Ejecuta el pipeline principal: `python src/main.py`
5.  Para iniciar la API, ejecuta:  `uvicorn src.api.main_api:app --host 0.0.0.0 --port 8000`
6.  Entra a este enlace para confirmar que funciona la API: `http://127.0.0.1:8000/`
7.  Entra a este enlace para hacer predicciones: `http://127.0.0.1:8000/docs`
8.  

### Opci贸n 3: Contenerizaci贸n con Docker (Recomendado)
La forma m谩s robusta y consistente de ejecutar la API es usando Docker. Este m茅todo asegura que la aplicaci贸n se ejecute en un entorno aislado con todas sus dependencias preinstaladas, evitando conflictos de versi贸n.

#### Requisitos Previos
**Docker Desktop**: Aseg煤rate de que Docker Desktop est谩 instalado y en ejecuci贸n en tu sistema.

#### Archivos Clave
`Dockerfile`: Contiene las instrucciones para construir la imagen de Docker.

`run-docker.ps1`: Un script de PowerShell que automatiza el proceso de construcci贸n y ejecuci贸n del contenedor.

#### Pasos para Contenerizar y Ejecutar
**Abre PowerShell**: Navega a la ra铆z del proyecto donde se encuentran los archivos `Dockerfile` y `run-docker.ps1`.

**Verifica la Configuraci贸n**: Aseg煤rate de que **Docker Desktop** est谩 en ejecuci贸n en tu sistema.

**Ejecuta el Script**: Corre el script de PowerShell para construir y lanzar el contenedor con un solo comando. Si es la primera vez que ejecutas un script local en PowerShell, es posible que necesites cambiar la pol铆tica de ejecuci贸n. Puedes hacerlo temporalmente con el siguiente comando (confirma con "S" o "A" si se te pide):

#### PowerShell

`Set-ExecutionPolicy RemoteSigned -Scope Process`
Una vez que la pol铆tica de ejecuci贸n est茅 configurada, corre el script de esta manera:

`.\run-docker.ps1`
**Verifica la Ejecuci贸n**: El script construir谩 la imagen y lanzar谩 el contenedor. Ver谩s mensajes en la terminal indicando el progreso. Si la ejecuci贸n es exitosa, el script te proporcionar谩 la URL para acceder a la API.

#### Acceso a la API Contenerizada
Una vez que el contenedor est茅 en ejecuci贸n, accede a la documentaci贸n de la API en tu navegador:
http://localhost:8000/docs